
<img src="kin.png" width="300"/> 

Kinesso, the Marketing Engine of IPG, is focused on creating data-driven solutions through enhanced or newly-created products and services, maximizing the impact of traditional and addressable media. Kinessoâ€™s core principle is to drive smarter business decisions and better outcomes for clients using our suite of data and technology services.

# Reinforcement Learning Challenge 2020

## Introduction:

Learning to act optimally on time series data is of practical uses in various industries. The value of taking an action depends on future actions and states, which makes it difficult to be modeled using a conventional machine leanrning techniques. This is where reinforcement learning comes in picture. In this challenge you will be working on multivariate time series data. To get started on the challenge begin by finding a multivariate time series dataset whose dependent variable is a real number and has finite action choices. 

## Eligibility: 
The challenge is open to current Northeastern University students.
The purpose of this challenge is to pre-screen candidates for a Programmer Analyst position during the Fall 2020. The position involves working closely with Kinesso. We sincerely hope you will participate to the challenge!!

## Resources:

- Reinforcement Learning - Thompson Sampling & the Multi-Armed Bandit Problem
https://colab.research.google.com/drive/1gdR7k7jtSRqYnPNHcbAKdIjGRjQXpfnA

https://github.com/nikbearbrown/Google_Colab/blob/master/Thompson_Sampling_%26_The_Multi_Armed_Bandit_Problem.ipynb

- Andre Cianflone - Thompson sampling
https://colab.research.google.com/drive/1BHVH712x2Q2As9E5nN5Y8UR74T8w6AMO



## The challenge:

1. Create a open-gym ai environment for that dataset to be run for an RL algorithm
2. Run one of the TF-Agents algorithms on it DQN, REINFORCE, DDPG, TD3, PPO or SAC
3. Compare the RL learner to a random action agent and simple agents like Thompson sampling, e-greedy, or UBC
4. Describe signals and action space for the five TF-Agents algorithms (DQN, REINFORCE, DDPG, TD3, PPO or SAC). Can they take continuous or only discrete signals? Can the agent only be used in any environment which has a discrete action space?
5. What are the pros and cons of the five TF-Agents algorithms (DQN, REINFORCE, DDPG, TD3, PPO or SAC).


## Your submission:

Deadline for the project is " ". The notebook should include a detailed analysis of our data, the models used and your scientific conclusions

When you're finished, please place the notebook and any other code you wrote into a zipped folder and e-mail to "ni.bear@northeastern.edu".



